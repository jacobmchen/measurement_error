{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "This notebook uses measurement error theory to recover the average causal effect between a treatment and outcome despite unmeasured confounding between the two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4809\n",
      "0.6326\n",
      "0.5626\n",
      "0.4951\n",
      "0.5464\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import statsmodels.api as sm\n",
    "\n",
    "np.random.seed(1)\n",
    "size = 10000\n",
    "verbose = True\n",
    "\n",
    "U = np.random.binomial(1, 0.48, size)\n",
    "if verbose:\n",
    "    print(np.mean(U))\n",
    "\n",
    "W = np.random.binomial(1, expit(1.3*U), size)\n",
    "if verbose:\n",
    "    print(np.mean(W))\n",
    "\n",
    "Z = np.random.binomial(1, expit(0.5*U), size)\n",
    "if verbose:\n",
    "    print(np.mean(Z))\n",
    "\n",
    "X = np.random.binomial(1, expit(0.8*U-0.4), size)\n",
    "if verbose:\n",
    "    print(np.mean(X))\n",
    "\n",
    "Y = np.random.binomial(1, expit(1.2*U+X-0.8), size)\n",
    "if verbose:\n",
    "    print(np.mean(Y))\n",
    "\n",
    "data = pd.DataFrame({\"U\": U, \"W\": W, \"X\": X, \"Y\": Y, \"Z\": Z})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confidence_intervals(X, Y, Z, W, data, method_name, num_bootstraps=200, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Compute confidence intervals for backdoor adjustment via bootstrap\n",
    "    \n",
    "    Returns tuple (q_low, q_up) for the lower and upper quantiles of the confidence interval.\n",
    "    \"\"\"\n",
    "    \n",
    "    Ql = alpha/2\n",
    "    Qu = 1 - alpha/2\n",
    "    # two lists for the two indexes of output\n",
    "    estimates0 = []\n",
    "    estimates1 = []\n",
    "    \n",
    "    for i in range(num_bootstraps):\n",
    "        \n",
    "        # resample the data with replacement\n",
    "        data_sampled = data.sample(len(data), replace=True)\n",
    "        data_sampled.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # add estimate from resampled data\n",
    "        if method_name == \"two proxy\":\n",
    "            output = two_proxy_effect_restoration(X, Y, Z, W, data_sampled)\n",
    "            estimates0.append(output[0])\n",
    "            estimates1.append(output[1])\n",
    "        else:\n",
    "            print(\"Invalid method\")\n",
    "            return\n",
    "\n",
    "    # calculate the quantiles\n",
    "    if method_name == \"two proxy\":\n",
    "        quantiles = np.quantile(estimates0, q=[Ql, Qu])\n",
    "        q_low0 = quantiles[0]\n",
    "        q_up0 = quantiles[1]\n",
    "\n",
    "        quantiles = np.quantile(estimates1, q=[Ql, Qu])\n",
    "        q_low1 = quantiles[0]\n",
    "        q_up1 = quantiles[1]\n",
    "    \n",
    "    return [(q_low0, q_up0), (q_low1, q_up1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect Restoration\n",
    "Code below attemps to recover p(X, Y, U) from p(X, Y, W) with additional information regarding p(W | U)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth values\n",
      "[0.2201, 0.0797, 0.0938, 0.1113, 0.0965, 0.0573, 0.1087, 0.2326]\n",
      "p(X=1 | U)\n",
      "[0.3952995569254479, 0.6028280307756291]\n"
     ]
    }
   ],
   "source": [
    "print(\"ground truth values\")\n",
    "\n",
    "groundTruth = []\n",
    "\n",
    "for i in range(8):\n",
    "    binString = format(i, '03b')\n",
    "\n",
    "    data_subset = data[data[\"X\"] == int(binString[0])]\n",
    "    data_subset = data_subset[data_subset[\"Y\"] == int(binString[1])]\n",
    "    data_subset = data_subset[data_subset[\"U\"] == int(binString[2])]\n",
    "\n",
    "    groundTruth.append(len(data_subset)/size)\n",
    "\n",
    "print(groundTruth)\n",
    "\n",
    "print(\"p(X=1 | U)\")\n",
    "pX_U = []\n",
    "data_subset = data[data[\"U\"] == 0]\n",
    "pX_U.append(np.mean(data_subset[\"X\"]))\n",
    "data_subset = data[data[\"U\"] == 1]\n",
    "pX_U.append(np.mean(data_subset[\"X\"]))\n",
    "print(pX_U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "given information: p(W | U)\n",
      "[0.4993257561163552, 0.5006742438836448, 0.2249948014140154, 0.7750051985859846]\n"
     ]
    }
   ],
   "source": [
    "print(\"given information: p(W | U)\")\n",
    "\n",
    "pWU = []\n",
    "\n",
    "for i in range(2):\n",
    "    binString = format(i, '01b')\n",
    "\n",
    "    data_subset = data[data[\"U\"] == int(binString[0])]\n",
    "\n",
    "    # we only want to consider where rows where U=u\n",
    "    subset_size = len(data_subset)\n",
    "    data_subset = data_subset[data_subset[\"W\"] == 0]\n",
    "\n",
    "    pWU.append(len(data_subset)/subset_size)\n",
    "\n",
    "    pWU.append(1 - (len(data_subset)/subset_size))\n",
    "\n",
    "print(pWU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def effect_restoration(X, Y, W, pWU, data):\n",
    "    # recover the target law p(X, Y, U) from the observed data distribution\n",
    "    # p(X, Y, W) from p(W | U), which is given information\n",
    "\n",
    "    # find the observed data distribution p(X, Y, W) from observed data\n",
    "    observedData = []\n",
    "\n",
    "    for i in range(8):\n",
    "        binString = format(i, '03b')\n",
    "\n",
    "        data_subset = data[data[X] == int(binString[0])]\n",
    "        data_subset = data_subset[data_subset[Y] == int(binString[1])]\n",
    "        data_subset = data_subset[data_subset[W] == int(binString[2])]\n",
    "\n",
    "        observedData.append(len(data_subset)/size)\n",
    "\n",
    "    # calculate the inverse matrix of p(W | U) needed for effect restoration\n",
    "    M = np.array([[pWU[0], pWU[1]], [(1-pWU[0]), (1-pWU[1])]])\n",
    "    I = np.linalg.inv(M)\n",
    "\n",
    "    # find the estimates for the target law p(X, Y, U) using matrix multiplication\n",
    "    estimates = []\n",
    "\n",
    "    for i in range(0, 8, 2):\n",
    "        pXYW = np.array([observedData[i], observedData[i+1]])\n",
    "        result = np.matmul(I, pXYW)\n",
    "\n",
    "        estimates.append(result[0])\n",
    "        estimates.append(result[1])\n",
    "\n",
    "    return estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target law:\n",
      "[0.2201, 0.0797, 0.0938, 0.1113, 0.0965, 0.0573, 0.1087, 0.2326]\n",
      "estimates:\n",
      "[0.20867699235105647, 0.09112300764894356, 0.10007462067040036, 0.10502537932959964, 0.09731238522277026, 0.05648761477722974, 0.11303600175577289, 0.2282639982442271]\n"
     ]
    }
   ],
   "source": [
    "print(\"target law:\")\n",
    "print(groundTruth)\n",
    "\n",
    "# recover the data distribution p(X, Y, U)\n",
    "\n",
    "print(\"estimates:\")\n",
    "pWU[1] = pWU[2]\n",
    "recovered_distribution = effect_restoration(\"X\", \"Y\", \"W\", pWU, data)\n",
    "print(recovered_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth values of p(X=1 | U):\n",
      "[0.3952995569254479, 0.6028280307756291]\n",
      "0.4052174667280739 0.5921222978196232\n"
     ]
    }
   ],
   "source": [
    "print(\"ground truth values of p(X=1 | U):\")\n",
    "print(pX_U)\n",
    "\n",
    "pX1U0 = recovered_distribution[4] + recovered_distribution[6]\n",
    "pX1U1 = recovered_distribution[5] + recovered_distribution[7]\n",
    "pU0 = recovered_distribution[0] + recovered_distribution[2] + recovered_distribution[4] + recovered_distribution[6]\n",
    "pU1 = recovered_distribution[1] + recovered_distribution[3] + recovered_distribution[5] + recovered_distribution[7]\n",
    "\n",
    "pX1_U0 = pX1U0/pU0\n",
    "pX1_U1 = pX1U1/pU1\n",
    "\n",
    "print(pX1_U0, pX1_U1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propensity Score Method\n",
    "Propensity score method for recovering p(X=1 | U)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_propensity_score(X, Y, W, pWU, data):\n",
    "    # given p(W=0 | U=0) and p(W=0 | U=1) and the joint distribution p(X, Y, W), recover the propensity score of being \n",
    "    # assigned the treatment p(X=1 | U=0) and p(X=1 | U=1)\n",
    "\n",
    "    # calculate the inverse matrix I\n",
    "    M = np.array([[pWU[0], pWU[1]], [(1-pWU[0]), (1-pWU[1])]])\n",
    "    I = np.linalg.inv(M)\n",
    "\n",
    "    # store the values of I as a, b, c, d\n",
    "    a = I[0][0]\n",
    "    b = I[0][1]\n",
    "    c = I[1][0]\n",
    "    d = I[1][1]\n",
    "\n",
    "    # find the observed data distribution p(X, Y, W) from observed data\n",
    "    observedData = []\n",
    "\n",
    "    for i in range(8):\n",
    "        binString = format(i, '03b')\n",
    "\n",
    "        data_subset = data[data[X] == int(binString[0])]\n",
    "        data_subset = data_subset[data_subset[Y] == int(binString[1])]\n",
    "        data_subset = data_subset[data_subset[W] == int(binString[2])]\n",
    "\n",
    "        observedData.append(len(data_subset)/size)\n",
    "\n",
    "    pX1W0 = observedData[4] + observedData[6]\n",
    "    pX1W1 = observedData[5] + observedData[7]\n",
    "    pW0 = observedData[0] + observedData[2] + observedData[4] + observedData[6]\n",
    "    pW1 = observedData[1] + observedData[3] + observedData[5] + observedData[7]\n",
    "\n",
    "    pX1_U0 = (a*pX1W0 + b*pX1W1) / (a*pW0 + b*pW1)\n",
    "    pX1_U1 = (c*pX1W0 + d*pX1W1) / (c*pW0 + d*pW1)\n",
    "\n",
    "    return (pX1_U0, pX1_U1)\n",
    "\n",
    "# def ipw_ace_recovery()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two proxy effect restoration.\n",
    "Code below attemps to recover p(X, Y, U) from p(X, Y, W, Z) without any other additional information.\n",
    "\n",
    "To calculate eigenvalues and eigenvectors, refer to the following Python documentation: https://numpy.org/doc/stable/reference/generated/numpy.linalg.eig.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth:\n",
      "0.4993257561163552 0.2249948014140154\n",
      "(0.4216957021144697, 0.038620553194038065)\n",
      "[(-0.2829846794195919, 0.395312987656183), (-0.7763841798813905, 0.5730249349340353)]\n",
      "\n",
      "ground truth values of p(X=1 | U):\n",
      "[0.3952995569254479, 0.6028280307756291]\n",
      "(0.45616891679407773, 0.7308413110344302)\n",
      "\n",
      "target law:\n",
      "[0.2201, 0.0797, 0.0938, 0.1113, 0.0965, 0.0573, 0.1087, 0.2326]\n",
      "[0.2952986077828918, 0.004501392217108254, 0.17145180188533957, 0.03364819811466045, 0.14451514037068425, 0.00928485962931576, 0.2469980249607057, 0.09430197503929433]\n"
     ]
    }
   ],
   "source": [
    "def two_proxy_effect_restoration(X, Y, Z, W, data):\n",
    "    # construct the matrix P(z, w) by using p(w=0 | x=0), p(z=0 | X=0), p(z=0, w=0 | X=0)\n",
    "    data_subsetX0 = data[data[X] == 1]\n",
    "    subset_size = len(data_subsetX0)\n",
    "\n",
    "    data_subset = data_subsetX0[data_subsetX0[W] == 0]\n",
    "    pW0_X0 = len(data_subset)/subset_size\n",
    "\n",
    "    data_subset = data_subsetX0[data_subsetX0[Z] == 0]\n",
    "    pZ0_X0 = len(data_subset)/subset_size\n",
    "\n",
    "    data_subset = data_subset[data_subset[W] == 0]\n",
    "    pZ0W0_X0 = len(data_subset)/subset_size\n",
    "\n",
    "    P = np.array([[1, pW0_X0], [pZ0_X0, pZ0W0_X0]])\n",
    "\n",
    "    # construct the matrix Q(z, w) by using p(y=0 | x=0), p(y=0, w=0 | x=0), p(y=0, z=0 | x=0), p(y=0, z=0, w=0 | x=0)\n",
    "    data_subset = data_subsetX0[data_subsetX0[Y] == 0]\n",
    "    pY0_X0 = len(data_subset)/subset_size\n",
    "\n",
    "    data_subset = data_subset[data_subset[W] == 0]\n",
    "    pY0W0_X0 = len(data_subset)/subset_size\n",
    "\n",
    "    data_subset = data_subsetX0[data_subsetX0[Y] == 0]\n",
    "    data_subset = data_subset[data_subset[Z] == 0]\n",
    "    pY0Z0_X0 = len(data_subset)/subset_size\n",
    "\n",
    "    data_subset = data_subset[data_subset[W] == 0]\n",
    "    pY0Z0W0_X0 = len(data_subset)/subset_size\n",
    "\n",
    "    Q = np.array([[pY0_X0, pY0W0_X0], [pY0Z0_X0, pY0Z0W0_X0]])\n",
    "\n",
    "    P_inv = np.linalg.inv(P)\n",
    "\n",
    "    # calculate the eigenvalues and eigenvectors of P(z, w)^{(-1)} * Q(z, w)\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(np.matmul(P_inv, Q))\n",
    "\n",
    "    # print(eigenvalues)\n",
    "\n",
    "    # find p(y=0 | x=0, u=0) and p(y=0 | x=0, u=1) to compare if the eigenvalues match up with\n",
    "    # those values as they should in theory\n",
    "    # data_subsetX0U0 = data_subsetX0[data_subsetX0[\"U\"] == 0]\n",
    "    # data_subset = data_subsetX0U0[data_subsetX0U0[\"Y\"] == 0]\n",
    "    # pY0_X0U0 = len(data_subset)/len(data_subsetX0U0)\n",
    "\n",
    "    # data_subsetX0U1 = data_subsetX0[data_subsetX0[\"U\"] == 1]\n",
    "    # data_subset = data_subsetX0U1[data_subsetX0U1[\"Y\"] == 0]\n",
    "    # pY0_X0U1 = len(data_subset)/len(data_subsetX0U1)\n",
    "    # print(pY0_X0U0, pY0_X0U1)\n",
    "    # print()\n",
    "\n",
    "    H_inv = np.linalg.inv(eigenvectors)\n",
    "\n",
    "    alpha_1 = 1/H_inv[0][0]\n",
    "    alpha_2 = 1/H_inv[1][0]\n",
    "\n",
    "    return (alpha_1*H_inv[0][1], alpha_2*H_inv[1][1])\n",
    "\n",
    "print(\"ground truth:\")\n",
    "print(pWU[0], pWU[2])\n",
    "pWU_estimates = two_proxy_effect_restoration(\"X\", \"Y\", \"Z\", \"W\", data)\n",
    "pWU_estimates = (pWU_estimates[1], pWU_estimates[0])\n",
    "print(pWU_estimates)\n",
    "print(compute_confidence_intervals(\"X\", \"Y\", \"Z\", \"W\", data, \"two proxy\"))\n",
    "print()\n",
    "\n",
    "print(\"ground truth values of p(X=1 | U):\")\n",
    "print(pX_U)\n",
    "prop_scores = recover_propensity_score(\"X\", \"Y\", \"W\", pWU_estimates, data)\n",
    "print(prop_scores)\n",
    "print()\n",
    "\n",
    "print(\"target law:\")\n",
    "print(groundTruth)\n",
    "recovered_distribution = effect_restoration(\"X\", \"Y\", \"W\", pWU_estimates, data)\n",
    "print(recovered_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
