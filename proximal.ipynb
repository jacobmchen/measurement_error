{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proximal Causal Inference Implementation\n",
    "The following code implements recovering the average causal effect between a treatment A on an outcome Y in the proximal causal inference setup where W and Z are proxies of U by fitting two linear regressions. Here, U, W, and Z are binary variables, so the first model is a linear logistic regression. On the other hand, Y is a continuous variable, so the second model is a normal linear logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58924\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import statsmodels.api as sm\n",
    "\n",
    "np.random.seed(0)\n",
    "size = 10000\n",
    "verbose = True\n",
    "\n",
    "# U = np.random.normal(0, 1, size)\n",
    "U = np.random.binomial(1, 0.48, size)\n",
    "\n",
    "# W = np.random.normal(0, 1, size) + 1.3*U\n",
    "W = np.random.binomial(1, expit(1.3*U), size)\n",
    "\n",
    "# Z = np.random.normal(0, 1, size) + 2*U\n",
    "Z = np.random.binomial(1, expit(2*U), size)\n",
    "\n",
    "A = np.random.binomial(1, expit(0.8*U), size)\n",
    "if verbose:\n",
    "    print(np.mean(A))\n",
    "\n",
    "Y = np.random.normal(0, 1, size) + 1.3*A + 1.4*U\n",
    "\n",
    "data = pd.DataFrame({\"U\": U, \"W\": W, \"A\": A, \"Y\": Y, \"Z\": Z})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code implementing estimating the average causal effect in the linear case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3468085291324319\n"
     ]
    }
   ],
   "source": [
    "def proximal_find_ace(A, Y, W, Z, data):\n",
    "    # fit a model W~A+Z\n",
    "    formula = W+\"~\"+A+\"+\"+Z\n",
    "    model1 = sm.GLM.from_formula(formula=formula, data=data, family=sm.families.Binomial()).fit()\n",
    "\n",
    "    # make predictions for What\n",
    "    What = model1.predict(data)\n",
    "    data[\"What\"] = What\n",
    "\n",
    "    # fit a model Y~A+What\n",
    "    formula = Y+\"~\"+A+\"+What\"\n",
    "    model2 = sm.GLM.from_formula(formula=formula, data=data, family=sm.families.Gaussian()).fit()\n",
    "\n",
    "    # the ACE is the coefficient for A in model2\n",
    "    return model2.params[1]\n",
    "\n",
    "print(proximal_find_ace(\"A\", \"Y\", \"W\", \"Z\", data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confidence_intervals(A, Y, W, Z, data, num_bootstraps=200, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Compute confidence intervals for backdoor adjustment via bootstrap\n",
    "    \n",
    "    Returns tuple (q_low, q_up) for the lower and upper quantiles of the confidence interval.\n",
    "    \"\"\"\n",
    "    \n",
    "    Ql = alpha/2\n",
    "    Qu = 1 - alpha/2\n",
    "    # two lists for the two indexes of output\n",
    "    estimates = []\n",
    "    \n",
    "    for i in range(num_bootstraps):\n",
    "        \n",
    "        # resample the data with replacement\n",
    "        data_sampled = data.sample(len(data), replace=True)\n",
    "        data_sampled.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # add estimate from resampled data\n",
    "        output = proximal_find_ace(A, Y, W, Z, data_sampled)\n",
    "        estimates.append(output)\n",
    "\n",
    "    # calculate the quantiles\n",
    "    quantiles = np.quantile(estimates, q=[Ql, Qu])\n",
    "    q_low = quantiles[0]\n",
    "    q_up = quantiles[1]\n",
    "    \n",
    "    return (q_low, q_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    U = np.random.binomial(1, 0.48, size)\n",
    "\n",
    "    X1 = np.random.normal(0, 1, size) + 2*U\n",
    "\n",
    "    # make sure that X2 is some non-linear function\n",
    "    X2 = np.random.normal(0, 1, size) + np.exp(X1) + U\n",
    "\n",
    "    X3 = np.random.normal(0, 1, size) + 1.3*U\n",
    "\n",
    "    # make sure that X4 is some non-linear function\n",
    "    X4 = np.random.normal(0, 1, size) + X3**2 + 0.5*X3**3 + U\n",
    "\n",
    "    A = np.random.binomial(1, expit(0.8*U), size)\n",
    "\n",
    "    Y = np.random.normal(0, 1, size) + 1.3*A + 1.4*U\n",
    "\n",
    "    data = pd.DataFrame({\"U\": U, \"X1\": X1, \"X2\": X2, \"X3\": X3, \"X4\": X4, \"A\": A, \"Y\": Y})\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Procedure Setup\n",
    "We first generate a dataset so that we can train two different models, one for predicting Z and one for predicting W. We then generate a second dataset according to the same DGP and make predictions for Z and W from that dataset. Using those predictions for Z and W, we use proximal causal inference to recover the ACE in the linear case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z accuracy:  0.86074\n",
      "W accuracy:  0.77368\n",
      "1.2920989264717164\n"
     ]
    }
   ],
   "source": [
    "data1 = generate_data()\n",
    "\n",
    "# fit a model U~X1+X2+X1*X2, this model will be used to predict Z\n",
    "# we add the interaction term to make sure that the model is non-linear\n",
    "modelZ = sm.GLM.from_formula(formula=\"U~X1+X2+X1*X2\", data=data1, family=sm.families.Binomial()).fit()\n",
    "# print(modelZ.params)\n",
    "\n",
    "# fit a model U~X3+X4+X3*X4, this model will be used to predict W\n",
    "modelW = sm.GLM.from_formula(formula=\"U~X3+X4+X3*X4\", data=data1, family=sm.families.Binomial()).fit()\n",
    "# print(modelW.params)\n",
    "\n",
    "data2 = generate_data()\n",
    "\n",
    "# make predictions for Z and W based off of our previosly trained models on a different dataset\n",
    "Z = modelZ.predict(data2)\n",
    "W = modelW.predict(data2)\n",
    "\n",
    "# evaluate the accuracy of the predictions for U when using modelZ\n",
    "cnt = 0\n",
    "correct_pred = 0\n",
    "for row in Z:\n",
    "    prediction = 0\n",
    "    if row > 0.5:\n",
    "        prediction = 1\n",
    "        \n",
    "    if prediction == data2[\"U\"][cnt]:\n",
    "        correct_pred += 1\n",
    "        \n",
    "    cnt += 1\n",
    "print(\"Z accuracy: \", correct_pred/len(Z))\n",
    "\n",
    "# evaluate the accuracy of the predictions for U when using modelW\n",
    "cnt = 0\n",
    "correct_pred = 0\n",
    "for row in W:\n",
    "    prediction = 0\n",
    "    if row > 0.5:\n",
    "        prediction = 1\n",
    "        \n",
    "    if prediction == data2[\"U\"][cnt]:\n",
    "        correct_pred += 1\n",
    "        \n",
    "    cnt += 1\n",
    "print(\"W accuracy: \", correct_pred/len(Z))\n",
    "\n",
    "# add the predictions into our dataframe\n",
    "data2[\"Z\"] = Z\n",
    "data2[\"W\"] = W\n",
    "\n",
    "print(proximal_find_ace(\"A\", \"Y\", \"W\", \"Z\", data2))\n",
    "print(compute_confidence_intervals(\"A\", \"Y\", \"W\", \"Z\", data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
